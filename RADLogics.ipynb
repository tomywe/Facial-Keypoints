{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RADLogics.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomywe/Facial-Keypoints/blob/master/RADLogics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ub1V4nvrwfHh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import zipfile\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as T\n",
        "\n",
        "import cv2\n",
        "\n",
        "from google.colab import files\n",
        "import io\n",
        "\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ov5KuRCzD6F6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "4cae0578-b0fe-4876-f34d-b43bc069535a"
      },
      "source": [
        "os.listdir()"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config',\n",
              " 'tiny-imagenet-200.zip',\n",
              " 'tiny-imagenet-200',\n",
              " 'alldata',\n",
              " 'sample_data']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIquiuHWwxgf",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "c4afa47f-6585-444b-b51b-a708f1150507"
      },
      "source": [
        "# upload tiny-imagenet-200 and lision data\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-beb07bd1-c31f-4971-b11c-18976f130ddb\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-beb07bd1-c31f-4971-b11c-18976f130ddb\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving tiny-imagenet-200.zip to tiny-imagenet-200.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JD8oQm4eQcoF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# extract images from zip files to directoris \n",
        "\n",
        "with zipfile.ZipFile('alldata.zip', 'r') as zipobj:\n",
        "  zipobj.extractall(path='alldata')\n",
        "with zipfile.ZipFile('tiny-imagenet-200.zip', 'r') as zipobj:\n",
        "  zipobj.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEplWpJu2PrE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cpu')\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3R8_lEyd_6o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LisionData(Dataset):\n",
        "  \n",
        "  def __init__(self, transform=None):\n",
        "    im_paths = os.listdir('alldata')\n",
        "    self.paths = im_paths\n",
        "    self.labels = np.array([self.get_label(path) for path in im_paths])\n",
        "    self.transform = transform\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.paths)\n",
        "    \n",
        "  def get_label(self, path):\n",
        "    path_split = path.split('_')\n",
        "    c = path_split[3].split('.')[0]\n",
        "    c = int(c)\n",
        "    return c\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    im = cv2.imread('alldata' + self.paths[index])\n",
        "    im = cv2.resize(im, (64,64), interpolation=cv2.INTER_CUBIC)\n",
        "    label = self.labels[index]\n",
        "    if self.transform is not None:\n",
        "      im = self.transform(im)\n",
        "      im = im.to(device)\n",
        "    return im, torch.tensor(label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIVWsytJgcGZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_k_fold_indexes(r, k=5):\n",
        "  indexes_lists = []\n",
        "  for _ in range(k):\n",
        "    indexes_lists.append([])\n",
        "  indexes = list(range(r))\n",
        "  i = 0\n",
        "  while len(indexes) > 0:\n",
        "    random_index = np.random.randint(len(indexes))\n",
        "    indexes_lists[i%k].append(indexes.pop(random_index))\n",
        "    i += 1\n",
        "  return indexes_lists\n",
        "\n",
        "lists = create_k_fold_indexes(182)\n",
        "test_indexes = lists.pop()\n",
        "val_indexes = lists.pop()\n",
        "train_indexes = []\n",
        "while len(lists) > 0:\n",
        "  train_indexes += lists.pop()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmbBN0Ohe1wl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TinyImageData(Dataset):\n",
        "  \n",
        "  def __init(self, transform=None, val=False):\n",
        "    image_names = []\n",
        "    labels = []\n",
        "    self.root_dir = 'tiny-imagenet-200/'\n",
        "    for d in os.listdir(self.root_dir):\n",
        "      train_names += os.listdir(self.root_dir 'train/' + d + '/images')\n",
        "      labels.append(dir)\n",
        "    data_table = pd.read_csv(self.root_dir + 'val/' + 'val_annotations.txt',\n",
        "                             sep='\\t', header=None)\n",
        "    val_names = pd[0]\n",
        "    val_labels = pd[1]\n",
        "    self.train_names = train_names\n",
        "    self.val_names = val_names\n",
        "    self.labels = labels\n",
        "    self.val_labels = val_labels\n",
        "    self.transform = transform\n",
        "    self.len = len(train_names)\n",
        "    if val:\n",
        "      self.len = len(val_names)\n",
        "    self.val = val\n",
        "    \n",
        "  def __len__(self):\n",
        "    return self.len\n",
        "  \n",
        "  def __getitem__(self.index):\n",
        "    if not self.val:\n",
        "      name = self.train_names[index]\n",
        "      name_split = name.split('_')\n",
        "      label = self.labels.index(name_split[0])\n",
        "      path = self.root_dir + 'train/' + self.labels[label] + '/images' + name\n",
        "    else:\n",
        "      name = self.val_names[index]\n",
        "      label = self.labels.index(self.val_labels[index])\n",
        "      path = self.root_dir + 'val/' + '/images' + name\n",
        "    im = cv2.imread(path)\n",
        "    if self.transform:\n",
        "      im = transform(im)\n",
        "    return im, torch.tensor(label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qahg2OQ609Cf",
        "colab_type": "code",
        "outputId": "04085cc5-09e3-45db-ef33-c01e2f88d0d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "norm_set = LisionData(transform=T.ToTensor())\n",
        "norm_loader = DataLoader(norm_set, batch_size=182)\n",
        "\n",
        "def compute_mean_std(loader):\n",
        "    mean = 0.0\n",
        "    var = 0.0\n",
        "    for images, _ in loader:\n",
        "        N, C, H, W = images.size()\n",
        "        images = images.view(N, C, -1)\n",
        "        mean += images.mean(2).sum(0)\n",
        "        var += ((images - mean.unsqueeze(1))**2).sum([0,2])\n",
        "    mean = mean / len(loader.dataset)\n",
        "    std = torch.sqrt(var / (len(loader.dataset)*H*W))\n",
        "    return mean, std\n",
        "\n",
        "mean, std = compute_mean_std(norm_loader)\n",
        "\n",
        "print(mean, std)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.6058, 0.6058, 0.6058], device='cuda:0') tensor([109.6499, 109.6499, 109.6499], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNVOuT8sgHqt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(), torchvision.transforms.Normalize(mean, std)])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZQiYOVu5GpD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_kfold_indexes(k, n_samples)\n",
        "  l = np.arange(n_samples)\n",
        "  a = np.random.choice(l, size=(,3), replace=False)\n",
        "  mask = np.ones(l.shape, dtype=bool)\n",
        "  mask[a.reshape(-1)] = False\n",
        "  last = l[mask]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhOCmbJAKaIR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Flatten(mm.Module):\n",
        "    def forward(self, input):\n",
        "        return input.view(input.size(0), -1)\n",
        "\n",
        "class k_fold_model(nn.Module):\n",
        "  def __init__():\n",
        "    super(k_fold_model, self).__init()\n",
        "    self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
        "    self.norm1 = nn.BatchNorm2d(32)\n",
        "    self.conv2_1 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "    self.norm2_1 = nn.BatchNorm2d(64)\n",
        "    self.conv2_2 = nn.Conv2d(64, 64, 3, padding=1)\n",
        "    self.nrom2_2 = nn.BatchNorm2d(64)\n",
        "    self.conv3_1 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "    self.nrom3_1 = nn.BatchNorm2d(128)\n",
        "    self.conv3_2 = nn.Conv2d(128, 128, 3, padding=1)\n",
        "    self.nrom3_2 = nn.BatchNorm2d(128)\n",
        "    self.conv4_1 = nn.Conv2d(128, 256, 3, 1)\n",
        "    self.nrom4_1 = nn.BatchNorm2d(256)\n",
        "    self.conv4_2 = nn.Conv2d(256, 16, 3, 1)\n",
        "    self.nrom4_2 = nn.BatchNorm2d(16)\n",
        "    self.fc1 = nn.Linear(4*4*16, 100)\n",
        "    self.fc2 = nn.Linear(100, 3)\n",
        "    self.pool = nn.MaxPool2d(2)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    # 1st conv module, input 64x64x3, output 32x32x64\n",
        "    x = self.conv1(x)\n",
        "    x = self.norm1(x)\n",
        "    x = self.pool(x)\n",
        "    x = F.relu(x)\n",
        "    # 2nd conv module, input 32x32x64, output 16x16x128\n",
        "    x = self.conv2_1(x)\n",
        "    x = self.norm2_1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.conv2_2(x)\n",
        "    x = self.norm2_2(x)\n",
        "    x = self.pool(x)\n",
        "    x = F.relu(x)\n",
        "    # 3rd conv module, input 16x16x128, output 4x4x256\n",
        "    x = self.conv3_1(x)\n",
        "    x = self.norm3_1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.conv3_2(x)\n",
        "    x = self.norm3_1(x)\n",
        "    x = self.pool(x)\n",
        "    x = F.relu(x)\n",
        "    # 4th conv module, input 4x4x256, output 4x4x16\n",
        "    x = self.conv4_1(x)\n",
        "    x = self.norm4_1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.conv4_2(x)\n",
        "    x = self.norm4_2(x)\n",
        "    x = F.relu(x)\n",
        "    # Fully connected layers to classifier\n",
        "    # 1st fc layer, input 256 output 100\n",
        "    x = Flatten(x)\n",
        "    x = self.fc1(x)\n",
        "    x = F.dropout2d(x)\n",
        "    x = self.relu(x)\n",
        "    # 2nd fc layer, input 100, output 3\n",
        "    x = self.fc2(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rdyg7ibVZC2F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resnet18 = models.resnet18()\n",
        "resnet18.fc = nn.Linear(512, 200)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1Wy2nira6-j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, optimizer, loader, val_loader, epochs=25):\n",
        "  train_loss = []\n",
        "  val_loss\n",
        "  for e in range(epochs):\n",
        "    for t, (data, labels) in enumerate(loader):\n",
        "      model.train()\n",
        "      scores = model(data)\n",
        "      loss = F.cross_entropy(scores, labels)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      oprimizer.step()\n",
        "      train_loss.append(loss)\n",
        "      # Print progress\n",
        "      if t%10 = 0:\n",
        "        print('ephoch {0} iteration {1} train loss {2}'.format(e, t, loss.item))\n",
        "        val_loss.append(accuracy(model, val_loader))\n",
        "        print()\n",
        "  return train_loss, val_loss\n",
        "\n",
        "def accuracy(model, loader):\n",
        "  loss_list = []\n",
        "  model.eval()\n",
        "  num_correct = 0\n",
        "  num_samples = 0\n",
        "  with torch.no_grad():\n",
        "    for data, labels in loader:\n",
        "      scores = model(data)\n",
        "      loss_list.append(F.cross_entropy(scores, labels))\n",
        "      _, preds = scores.argmax(1)\n",
        "      num_correct += (preds == labels).sum()\n",
        "      num_samples += len(labels)\n",
        "    acc = float(num_correct) / num_samples\n",
        "    print('got {0} / {1} correct at {2}%'.format(num_correct, num_samples, acc)\n",
        "    return np.mean(loss_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ep8s9nFxhyVw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_lr(model_class, train_loader, val_loader):\n",
        "  best_model = None\n",
        "  best_lr = np.ln(3)\n",
        "  for lr in [1, 1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6]:\n",
        "    model = model_class()\n",
        "    optimizer = optim.Adam(model.parameters, lr=lr)\n",
        "    train_loss, val_loss = train(model, optimizer, train_loader, val_loader, epochs=5)\n",
        "    if train_loss[-1] < best_loss:\n",
        "      best_loss = loss[-1]\n",
        "      best_lr = lr\n",
        "  return best_lr\n",
        "\n",
        "best_lr = find_lr(k_fold_model, train_loader, val_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6h9EmxNb26r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "d41f8118-68eb-422e-ca4d-5a9824035e06"
      },
      "source": [
        "model_list = []\n",
        "optimizer_list = []\n",
        "for _ in range(k):\n",
        "  model_list.append(k_fold_model())\n",
        "  optimizer_list.append(optim.Adam(model_list[i].parameters, lr=best_lr))\n",
        "  train(model_list[-1], optimizer_list[-1], train_loader, val_loader, epochs=50)\n",
        "  \n",
        "test_list = []\n",
        "for model in model_list:\n",
        "  test_list.append(model(test_data))\n",
        "test_result = np.mean(test_list, axis=0)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-720be3b8e7f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk_fold_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'k' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jhQshUFhKcl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr_resnet = find_lr(resnet18, )\n",
        "train(resnet18, res_optim, res_train_loader, res_val_loader)\n",
        "\n",
        "plt.imshow(train_loss)\n",
        "plt.imshow(val_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGt1bbKGmxM9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1445
        },
        "outputId": "c3cc136e-db90-4a4c-8146-5f77ff8eb499"
      },
      "source": [
        "resnet18"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBR_49Kum6ad",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resnet18.fc = nn.Linear(512, 3)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}